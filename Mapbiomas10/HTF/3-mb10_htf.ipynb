{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Bibliotecas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T16:44:37.356456Z",
     "iopub.status.busy": "2025-02-17T16:44:37.356185Z",
     "iopub.status.idle": "2025-02-17T16:45:21.460023Z",
     "shell.execute_reply": "2025-02-17T16:45:21.459341Z",
     "shell.execute_reply.started": "2025-02-17T16:44:37.356432Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "import tensorflow as tf\n",
    "import ee\n",
    "import numpy as np\n",
    "from osgeo import ogr\n",
    "from osgeo import gdal\n",
    "import glob,pygeoj\n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "from patchify import patchify, unpatchify\n",
    "\n",
    "\n",
    "import json\n",
    "import math\n",
    "import logging\n",
    "import time\n",
    "from datetime import datetime, date, timedelta\n",
    "\n",
    "import folium\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import Image\n",
    "\n",
    "logging.getLogger('googleapicliet.discovery_cache').setLevel(logging.ERROR)\n",
    "\n",
    "gpu_dict    = {'4090':{'GPU_AFFINTY' : 0, 'GPU_MEMORY_LIMIT_GB':12}}\n",
    "sel_gpu     = '4090'\n",
    "GPU_AFFINTY = gpu_dict[sel_gpu]['GPU_AFFINTY'] \n",
    "GPU_MEMORY_LIMIT_GB = gpu_dict[sel_gpu]['GPU_MEMORY_LIMIT_GB']\n",
    "USER_EE_PROJECT='USER_PROJECT_ID'\n",
    "\n",
    "try:\n",
    "    ee.Initialize(project = USER_EE_PROJECT)\n",
    "except:\n",
    "    ee.Authenticate()\n",
    "    ee.Initialize(project = USER_EE_PROJECT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T16:45:24.746775Z",
     "iopub.status.busy": "2025-02-17T16:45:24.746417Z",
     "iopub.status.idle": "2025-02-17T16:45:24.892915Z",
     "shell.execute_reply": "2025-02-17T16:45:24.892525Z",
     "shell.execute_reply.started": "2025-02-17T16:45:24.746750Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "EE_TILES = 'https://earthengine.googleapis.com/map/{mapid}/{{z}}/{{x}}/{{y}}?token={token}'\n",
    "\n",
    "print('Tensorflow Version:',tf.__version__)\n",
    "print('Folium Version:',folium.__version__)\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "  try:\n",
    "    tf.config.set_visible_devices(gpus[GPU_AFFINTY], 'GPU')\n",
    "    GPU_MEMORY_LIMIT_GB = GPU_MEMORY_LIMIT_GB * 1e3\n",
    "    if GPU_MEMORY_LIMIT_GB == 0:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    else:\n",
    "        tf.config.set_logical_device_configuration(gpus[GPU_AFFINTY],[tf.config.LogicalDeviceConfiguration(memory_limit=GPU_MEMORY_LIMIT_GB)])\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T16:45:27.166065Z",
     "iopub.status.busy": "2025-02-17T16:45:27.165754Z",
     "iopub.status.idle": "2025-02-17T16:45:27.169288Z",
     "shell.execute_reply": "2025-02-17T16:45:27.168608Z",
     "shell.execute_reply.started": "2025-02-17T16:45:27.166045Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_directory(new_folder):\n",
    "  ''' Check if any of the specified folder already exist'''\n",
    "  if not os.path.exists(new_folder):\n",
    "      print(f'lets make the directory: {new_folder}')\n",
    "      os.makedirs(new_folder)\n",
    "  else: return\n",
    "\n",
    "  def check_file_exists(paths):\n",
    "    \"\"\"Check if any of the specified paths already exist\"\"\"\n",
    "    for path in paths:\n",
    "        if os.path.exists(path):\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENV Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T16:45:28.182840Z",
     "iopub.status.busy": "2025-02-17T16:45:28.182552Z",
     "iopub.status.idle": "2025-02-17T16:45:28.191701Z",
     "shell.execute_reply": "2025-02-17T16:45:28.191028Z",
     "shell.execute_reply.started": "2025-02-17T16:45:28.182815Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# General \n",
    "GPU_AFFINITY   = gpus[GPU_AFFINTY].name\n",
    "MOSAIC_VERSION = '1'\n",
    "MAPBIOMAS_V    = '10'\n",
    "\n",
    "VERSION        = '4_p5_DATA_AUGMENTATION'\n",
    "MOSAIC_VERSION = '1'\n",
    "\n",
    "\n",
    "GOAL_YEAR      = '2022'\n",
    "GOAL_CLASS     = 'htf'\n",
    "GDRIVE         = f'mb{MAPBIOMAS_V}-unet-htf-brazil_'+VERSION\n",
    "\n",
    "FOLDER_TRAIN   = f'mb{MAPBIOMAS_V}_htf_training_samples'\n",
    "FOLDER_TEST    = f'mb{MAPBIOMAS_V}_htf_eval_samples'\n",
    "\n",
    "TRAINING_BASE  = 'training_patches_'+MOSAIC_VERSION+'_v'+SAMPLE_VERSION\n",
    "EVAL_BASE      = 'eval_patches_'+MOSAIC_VERSION+'_v'+SAMPLE_VERSION\n",
    "\n",
    "#Local paths\n",
    "CURRENT_LOCAL_PATH  = f'~/Mapbiomas/modelos/mb{MAPBIOMAS_V}-unet-{GOAL_CLASS}' \n",
    "\n",
    "MODEL_DIR   = f'{CURRENT_LOCAL_PATH}/checkpoint/v{VERSION}'\n",
    "OUTPUT_PATH = CURRENT_LOCAL_PATH+'/output/v'+VERSION\n",
    "create_directory(MODEL_DIR)\n",
    "create_directory(OUTPUT_PATH)\n",
    "\n",
    "\n",
    "# Specify inputs (Landsat bands) to the model and the response variable.\n",
    "opticalBands   = ['green','red','nir','swir1']\n",
    "opticalIndices = ['NDVI','MNDWI']\n",
    "BANDS          = opticalBands + opticalIndices\n",
    "\n",
    "RESPONSE = 'supervised'\n",
    "FEATURES = BANDS + [RESPONSE]\n",
    "\n",
    "# Specify the size and shape of patches expected by the model.\n",
    "KERNEL_SIZE  = 256\n",
    "KERNEL_SHAPE = [KERNEL_SIZE, KERNEL_SIZE]\n",
    "COLUMNS = [\n",
    "  tf.io.FixedLenFeature(shape=KERNEL_SHAPE, dtype=tf.float32) for k in FEATURES\n",
    "]\n",
    "FEATURES_DICT = dict(zip(FEATURES, COLUMNS))\n",
    "\n",
    "# Sizes of the training and evaluation datasets.\n",
    "TRAIN_SIZE = 0\n",
    "EVAL_SIZE  = 0\n",
    "\n",
    "\n",
    "# Specify model training parameters.\n",
    "BATCH_SIZE  = 10 \n",
    "DROPOUT     = 0.3 \n",
    "EPOCHS      = 50\n",
    "BUFFER_SIZE = 1000 \n",
    "OPTIMIZER   = 'Nadam' \n",
    "LOSS        = 'BinaryCrossentropy'\n",
    "METRICS     = ['RootMeanSquaredError']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "baseClassV       = '4'\n",
    "yearClass_class  = '2022'\n",
    "yearClass_mosaic = '2022'\n",
    "version_final    = '4'\n",
    "classID          = 32\n",
    "\n",
    "USER_PATH_MOSAIC = 'USER_PATH_MOSAIC'\n",
    "\n",
    "supervised_layer  = ee.Image('projects/solved-mb10/assets/public/LANDSAT/HTF/'+yearClass_class+'-'+version_final+'_SUPERVISEDMASK_FULL').eq(classID).rename(RESPONSE)\n",
    "supervisedChannel = supervised_layer.toByte().rename(RESPONSE)\n",
    "\n",
    "\n",
    "image = ee.Image('projects/'+USER_EE_PROJECT+'/assets/'+USER_PATH_MOSAIC+'/mosaic_'+yearClass_mosaic).addBands(supervisedChannel)\n",
    "mapid = image.getMapId({'bands': ['red', 'green', 'blue'], 'min': 11, 'max': 95})\n",
    "\n",
    "map = folium.Map(location=[-23.0089, -43.6078],zoom_start=13)\n",
    "folium.TileLayer(\n",
    "    tiles=mapid['tile_fetcher'].url_format,\n",
    "    attr='Planet',\n",
    "    overlay=True,\n",
    "    name='Mosaic composite',\n",
    "  ).add_to(map)\n",
    "mapid = supervisedChannel.select(RESPONSE).mask(supervisedChannel.eq(1)).getMapId({'min': 0, 'max': 1, 'palette':'red'})\n",
    "folium.TileLayer(\n",
    "    tiles=mapid['tile_fetcher'].url_format,\n",
    "    attr='Google Earth Engine',\n",
    "    overlay=True,\n",
    "    name='Apicum '+yearClass_class,\n",
    "  ).add_to(map)\n",
    "map.add_child(folium.LayerControl())\n",
    "map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "featureStack = ee.Image.cat([\n",
    "  image.select(BANDS).unmask(0),\n",
    "  image.select(RESPONSE).unmask(0)\n",
    "]).float()\n",
    "\n",
    "list = ee.List.repeat(1, KERNEL_SIZE)\n",
    "lists = ee.List.repeat(list, KERNEL_SIZE)\n",
    "kernel = ee.Kernel.fixed(KERNEL_SIZE, KERNEL_SIZE, lists)\n",
    "\n",
    "arrays = featureStack.neighborhoodToArray(kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "yearClass_geoms = '2020'\n",
    "trainingPolys_v1 = ee.FeatureCollection('projects/solved-mb10/assets/public/LANDSAT/HTF/trainPolys_htf_'+yearClass_geoms+'_v1')\n",
    "evalPolys_v1     = ee.FeatureCollection('projects/solved-mb10/assets/public/LANDSAT/HTF/testPolys_htf_'+yearClass_geoms+'_v1')\n",
    "\n",
    "trainingPolys_v2 = ee.FeatureCollection('projects/solved-mb10/assets/public/LANDSAT/HTF/trainPolys_htf_'+yearClass_geoms+'_v2_update')\n",
    "evalPolys_v2     = ee.FeatureCollection('projects/solved-mb10/assets/public/LANDSAT/HTF/testPolys_htf_'+yearClass_geoms+'_v2_update')\n",
    "\n",
    "trainingPolys_v3 = ee.FeatureCollection('projects/solved-mb10/assets/public/LANDSAT/HTF/trainPolys_htf_'+str(2022)+'_v3')\n",
    "evalPolys_v3     = ee.FeatureCollection('projects/solved-mb10/assets/public/LANDSAT/HTF/testPolys_htf_'+str(2022)+'_v3')\n",
    "\n",
    "trainingPolys = trainingPolys_v1.merge(trainingPolys_v2)\n",
    "evalPolys     = evalPolys_v1.merge(evalPolys_v2).merge(evalPolys_v3)\n",
    "\n",
    "id_filter_out = ['2_00000000000000000018','2_0000000000000000001f','1_00000000000000000004','2_0000000000000000001d']\n",
    "trainingPolys = trainingPolys.filter(ee.Filter.inList('system:index', id_filter_out).Not())\n",
    "\n",
    "trainingPolys = trainingPolys.merge(trainingPolys_v3)\n",
    "\n",
    "def geo_type(feature):\n",
    "    return feature.set('geo_type', feature.geometry().type())\n",
    "trainingPolys = trainingPolys.map(lambda feat: geo_type(feat))\n",
    "trainingPolys = trainingPolys.filter(ee.Filter.neq('geo_type','LineString'))\n",
    "\n",
    "print(trainingPolys.size().getInfo())\n",
    "print(evalPolys.size().getInfo())\n",
    "\n",
    "polyImage = ee.Image(0).byte().paint(trainingPolys, 1).paint(evalPolys, 2)\n",
    "polyImage = polyImage.updateMask(polyImage)\n",
    "\n",
    "mapid = polyImage.getMapId({'min': 1, 'max': 2, 'palette': ['red', 'blue']})\n",
    "map = folium.Map(location=[-1.3621, -45.2738], zoom_start=5)\n",
    "folium.TileLayer(\n",
    "    tiles=mapid['tile_fetcher'].url_format,\n",
    "    attr='Google Earth Engine',\n",
    "    overlay=True,\n",
    "    name='training polygons',\n",
    "  ).add_to(map)\n",
    "map.add_child(folium.LayerControl())\n",
    "# map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Train/Test Chips Exportation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "version_samples_acc = \"4\"\n",
    "\n",
    "# Convert the feature collections to lists for iteration.\n",
    "trainingPolysList = trainingPolys.toList(trainingPolys.size())\n",
    "evalPolysList = evalPolys.toList(evalPolys.size())\n",
    "# These numbers determined experimentally.\n",
    "n = 20 # Number of shards in each polygon.\n",
    "N = 200 # Total sample size in each polygon.\n",
    "FOLDER_TEST    = 'testing_samples_FOR_DEEPLABV3'\n",
    "\n",
    "\n",
    "#Add some generalism\n",
    "TRAIN_SIZE = trainingPolys.size().getInfo()*N\n",
    "EVAL_SIZE = evalPolys.size().getInfo()*N\n",
    "print('TRAIN:'+str(TRAIN_SIZE))\n",
    "print('EVAL:'+str(EVAL_SIZE))\n",
    "GDRIVE = 'MB8_Apicum_v5'\n",
    "# Export all the training data (in many pieces), with one task \n",
    "# per geometry.\n",
    "for g in range(trainingPolys.size().getInfo()):\n",
    "  geomSample = ee.FeatureCollection([])\n",
    "  for i in range(n):\n",
    "    sample = arrays.sample(\n",
    "      region = ee.Feature(trainingPolysList.get(g)).geometry(), \n",
    "      scale = 30, \n",
    "      numPixels = N / n, # Size of the shard.\n",
    "      seed = i,\n",
    "      tileScale = 8\n",
    "    )\n",
    "    geomSample = geomSample.merge(sample)\n",
    "  \n",
    "  desc = TRAINING_BASE + '_g' + str(g)\n",
    "  task = ee.batch.Export.table.toDrive(\n",
    "    collection = geomSample,\n",
    "    description = desc, \n",
    "    folder = GDRIVE+'/'+FOLDER_TRAIN+'_v'+version_samples_acc, \n",
    "    fileNamePrefix = desc,\n",
    "    fileFormat = 'TFRecord',\n",
    "    selectors = BANDS + [RESPONSE]\n",
    "  )\n",
    "  # task.start()\n",
    "\n",
    "# Export all the evaluation data.\n",
    "for g in range(evalPolys.size().getInfo()):\n",
    "  geomSample = ee.FeatureCollection([])\n",
    "  for i in range(n):\n",
    "    sample = arrays.sample(\n",
    "      region = ee.Feature(evalPolysList.get(g)).geometry(), \n",
    "      scale = 30, \n",
    "      numPixels = N / n,\n",
    "      seed = i,\n",
    "      tileScale = 8\n",
    "    )\n",
    "    geomSample = geomSample.merge(sample)\n",
    "  \n",
    "  desc = EVAL_BASE + '_g' + str(g)\n",
    "  task = ee.batch.Export.table.toDrive(\n",
    "    collection = geomSample,\n",
    "    description = desc, \n",
    "    folder = GDRIVE+'/'+FOLDER_TEST+version_samples_acc, \n",
    "    fileNamePrefix = desc,\n",
    "    fileFormat = 'TFRecord',\n",
    "    selectors = BANDS + [RESPONSE],\n",
    "  )\n",
    "  # task.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parse_tfrecord(example_proto):\n",
    "  \"\"\"The parsing function.\n",
    "  Read a serialized example into the structure defined by FEATURES_DICT.\n",
    "  Args:\n",
    "    example_proto: a serialized Example.\n",
    "  Returns: \n",
    "    A dictionary of tensors, keyed by feature name.\n",
    "  \"\"\"\n",
    "  print(FEATURES_DICT)\n",
    "  return tf.io.parse_single_example(example_proto, FEATURES_DICT)\n",
    "\n",
    "\n",
    "\n",
    "def to_tuple(inputs):\n",
    "  \"\"\"Function to convert a dictionary of tensors to a tuple of (inputs, outputs).\n",
    "  Turn the tensors returned by parse_tfrecord into a stack in HWC shape.\n",
    "  Args:\n",
    "    inputs: A dictionary of tensors, keyed by feature name.\n",
    "  Returns: \n",
    "    A dtuple of (inputs, outputs).\n",
    "  \"\"\"\n",
    "  inputsList = [inputs.get(key) for key in FEATURES]\n",
    "  stacked = tf.stack(inputsList, axis=0)\n",
    "  # Convert from CHW to HWC\n",
    "  stacked = tf.transpose(stacked, [1, 2, 0])\n",
    "  return stacked[:,:,:len(BANDS)], stacked[:,:,len(BANDS):]\n",
    "\n",
    "\n",
    "def get_dataset(pattern):\n",
    "  \"\"\"Function to read, parse and format to tuple a set of input tfrecord files.\n",
    "  Get all the files matching the pattern, parse and convert to tuple.\n",
    "  Args:\n",
    "    pattern: A file pattern to match in a Cloud Storage bucket.\n",
    "  Returns: \n",
    "    A tf.data.Dataset\n",
    "  \"\"\"\n",
    "  # glob = tf.gfile.Glob(pattern) for tendorflow 1.x\n",
    "  glob = tf.io.gfile.glob(pattern) # for tendorflow 2.x\n",
    "  dataset = tf.data.TFRecordDataset(glob, compression_type='GZIP')\n",
    "  dataset = dataset.map(parse_tfrecord, num_parallel_calls=5)\n",
    "  dataset = dataset.map(to_tuple, num_parallel_calls=5)\n",
    "  return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "import copy\n",
    "import random\n",
    "seed = 42\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "data_augmentation_model = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"vertical\", seed=seed),\n",
    "    layers.RandomRotation(factor=0.2, seed=seed),\n",
    "    layers.RandomTranslation(height_factor=0.1, width_factor=0.1, seed=seed)\n",
    "])\n",
    "\n",
    "def create_data_augmentation_v2(model):\n",
    "\n",
    "    return model\n",
    "\n",
    "def augment_fn(x, y):\n",
    "    # data_augmentation_func = create_data_augmentation(seed)\n",
    "    data_augmentation_func = create_data_augmentation_v2(data_augmentation_model)\n",
    "    input_data = tf.concat([x, y], axis=-1)\n",
    "    \n",
    "    # Check if the instance contains your target class\n",
    "    tensor_sum_value  = tf.math.reduce_sum(y, axis=[0,1,2])\n",
    "    tensor_base_value = tf.constant([183.], dtype=tf.float32)\n",
    "    greater_tensor    = tf.greater(tensor_sum_value, tensor_base_value)\n",
    "\n",
    "    if tf.reduce_any(greater_tensor):\n",
    "        augmented_data = data_augmentation_func(input_data)\n",
    "        x_aug = augmented_data[:, :, :len(BANDS)]\n",
    "        y_aug = augmented_data[:, :, len(BANDS):]\n",
    "        return (x_aug, y_aug)\n",
    "    else:\n",
    "        return (x, y)\n",
    "    \n",
    "def is_augmented(x, y):\n",
    "    tensor_sum_value  = tf.math.reduce_sum(y, axis=[0,1,2])\n",
    "    tensor_base_value = tf.constant([183.], dtype=tf.float32)\n",
    "    greater_tensor    = tf.greater(tensor_sum_value, tensor_base_value)\n",
    "    return tf.reduce_any(greater_tensor)\n",
    "\n",
    "\n",
    "def get_training_dataset_data_aug_target(SAMPLE_PATH):\n",
    "    \"\"\"Get the preprocessed training dataset\n",
    "  Returns: \n",
    "    A tf.data.Dataset of training data.\n",
    "  \"\"\"\n",
    "    \n",
    "    glob    = SAMPLE_PATH + '/'+ TRAINING_BASE + '*'   \n",
    "    dataset_bkp = get_dataset(glob)\n",
    "    dataset     = get_dataset(glob)\n",
    "    print('\\n')\n",
    "    \n",
    "    \n",
    "    num_samples = 31800\n",
    "    \n",
    "    for index in range(1):\n",
    "        augmented_dataset = dataset_bkp.map(augment_fn)\n",
    "        augmented_only_dataset = augmented_dataset.filter(is_augmented).take(15900)\n",
    "        dataset = dataset.concatenate(augmented_only_dataset)\n",
    "    \n",
    "    dataset = dataset.shuffle(BUFFER_SIZE, reshuffle_each_iteration=True).batch(8).repeat().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "version_samples_acc = \"4_p5\"\n",
    "TRAIN_PATH = CURRENT_LOCAL_PATH+'/train/v'+version_samples_acc\n",
    "create_directory(TRAIN_PATH)\n",
    "training = get_training_dataset_data_aug_target(TRAIN_PATH)\n",
    "print(training.take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_eval_dataset(SAMPLE_PATH):\n",
    "    glob    = SAMPLE_PATH + '/'+ EVAL_BASE + '*'\n",
    "    dataset = get_dataset(glob)\n",
    "    dataset = dataset.batch(1).repeat()\n",
    "    return dataset\n",
    "\n",
    "version_samples_acc = \"4_p5\"\n",
    "EVAL_PATH = CURRENT_LOCAL_PATH+'/eval/v'+version_samples_acc\n",
    "create_directory(EVAL_PATH)\n",
    "evaluation = get_eval_dataset(EVAL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def previewClass(epoch,log):\n",
    "    counter = 0\n",
    "    for batch in evaluation.shuffle(1000).take(3):\n",
    "        pureImage = batch[0]\n",
    "        supervised = batch[1]\n",
    "        stacked = tf.transpose(pureImage[0], [0, 1, 2]).numpy()\n",
    "        stackedS = tf.transpose(supervised[0], [0, 1, 2]).numpy()\n",
    "\n",
    "        test_pred_raw = m.predict(pureImage)\n",
    "        test_pred_raw = tf.transpose(test_pred_raw[0],[0, 1, 2]).numpy()\n",
    "        fig = plt.figure(figsize=[12,4])\n",
    "        # show original image\n",
    "        fig.add_subplot(131)\n",
    "        plt.imshow(stacked[:,:,0:3].astype(np.uint8), interpolation='nearest', vmin=0, vmax=255)\n",
    "        fig.add_subplot(132)\n",
    "        plt.imshow(stackedS[:,:,0], interpolation='nearest',cmap=\"gray\")\n",
    "        fig.add_subplot(133)\n",
    "        plt.imshow(test_pred_raw[:,:,0], interpolation='nearest',cmap=\"gray\")\n",
    "        plt.show()\n",
    "        counter = counter+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# UNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "\n",
    "def conv_block(input_tensor, num_filters):\n",
    "\tencoder = layers.Conv2D(num_filters, (3, 3), padding='same')(input_tensor)\n",
    "\tencoder = layers.BatchNormalization()(encoder)\n",
    "\tencoder = layers.Activation('relu')(encoder)\n",
    "\tencoder = layers.Conv2D(num_filters, (3, 3), padding='same')(encoder)\n",
    "\tencoder = layers.BatchNormalization()(encoder)\n",
    "\tencoder = layers.Activation('relu')(encoder)\n",
    "\treturn encoder\n",
    "\n",
    "def encoder_block_ori_unet(input_tensor, num_filters):\n",
    "\tencoder = conv_block(input_tensor, num_filters)\n",
    "\tencoder_pool = layers.MaxPooling2D((2, 2), strides=(2, 2))(encoder)\n",
    "\treturn encoder_pool, encoder\n",
    "\n",
    "def decoder_block(input_tensor, concat_tensor, num_filters):\n",
    "\tdecoder = layers.Conv2DTranspose(num_filters, (2, 2), strides=(2, 2), padding='same')(input_tensor)\n",
    "\tdecoder = layers.concatenate([concat_tensor, decoder], axis=-1)\n",
    "\tdecoder = layers.BatchNormalization()(decoder)\n",
    "\tdecoder = layers.Activation('relu')(decoder)\n",
    "\tdecoder = layers.Conv2D(num_filters, (3, 3), padding='same')(decoder)\n",
    "\tdecoder = layers.BatchNormalization()(decoder)\n",
    "\tdecoder = layers.Activation('relu')(decoder)\n",
    "\tdecoder = layers.Conv2D(num_filters, (3, 3), padding='same')(decoder)\n",
    "\tdecoder = layers.BatchNormalization()(decoder)\n",
    "\tdecoder = layers.Activation('relu')(decoder)\n",
    "\treturn decoder\n",
    "\n",
    "def get_model():\n",
    "\tinputs = layers.Input(shape=[None, None, len(BANDS)]) # 256 (shape=[256, 256, len(BANDS\n",
    "\tencoder0_pool, encoder0 = encoder_block_ori_unet(inputs, 64) # 128\n",
    "\tencoder1_pool, encoder1 = encoder_block_ori_unet(encoder0_pool, 128) # 64\n",
    "\tencoder2_pool, encoder2 = encoder_block_ori_unet(encoder1_pool, 256) # 32\n",
    "\tencoder3_pool, encoder3 = encoder_block_ori_unet(encoder2_pool, 512) # 16\n",
    "\tcenter = conv_block(encoder3_pool, 1024) # 8 center\n",
    "\tdecoder4 = decoder_block(center, encoder3, 512) # 16\n",
    "\tdecoder3 = decoder_block(decoder4, encoder2, 256) # 32\n",
    "\tdecoder2 = decoder_block(decoder3, encoder1, 128) # 64\n",
    "\tdecoder1 = decoder_block(decoder2, encoder0, 64) # 128\n",
    "\tdropout = layers.Dropout(DROPOUT, name=\"dropout\", noise_shape=None, seed=None)(decoder1)\n",
    "\n",
    "\n",
    "\toutputs = layers.Conv2D(1, (1, 1),  activation=tf.nn.sigmoid, padding='same', kernel_initializer=tf.keras.initializers.GlorotNormal())(dropout) #tensorflow 2.x    \n",
    "\tmodel = models.Model(inputs=[inputs], outputs=[outputs])\n",
    "\toptimizer = tf.keras.optimizers.Nadam(0.000005, name='optimizer')\n",
    "\n",
    "\tmodel.compile(\n",
    "\t\toptimizer=optimizer, \n",
    "\t\tloss=losses.get(LOSS),\n",
    "\t\tmetrics=[metrics.get(metric) for metric in METRICS]\n",
    "    )\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# FCN-DK (FCN with dilated kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T16:45:52.744222Z",
     "iopub.status.busy": "2025-02-17T16:45:52.743928Z",
     "iopub.status.idle": "2025-02-17T16:45:54.227805Z",
     "shell.execute_reply": "2025-02-17T16:45:54.227387Z",
     "shell.execute_reply.started": "2025-02-17T16:45:52.744197Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "loaded_model = get_model()\n",
    "EPOCH = 0\n",
    "if EPOCH>0:\n",
    "    LOADED_MODEL_DIR = f'{MODEL_DIR}/cp-00{str(EPOCH)}.keras'\n",
    "    loaded_model.load_weights(LOADED_MODEL_DIR)\n",
    "print(loaded_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "checkpoint_path = MODEL_DIR+\"/cp-{epoch:04d}.keras\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "create_directory(checkpoint_dir)\n",
    "print(checkpoint_dir)\n",
    "\n",
    "\n",
    "n = 20 # Number of shards in each polygon.\n",
    "N = 200 # Total sample size in each polygon.\n",
    "TRAIN_SIZE = trainingPolys.size().getInfo()*N\n",
    "EVAL_SIZE = evalPolys.size().getInfo()*N\n",
    "\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(log_dir=f'output/v{VERSION}/log_model',write_images=True)\n",
    "cp_callback  = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,verbose=1, save_weights_only=False,save_best_only=False,save_freq='epoch')\n",
    "img_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end=previewClass)\n",
    "earlyStopping_callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10)\n",
    "\n",
    "\n",
    "\n",
    "TRAIN_SIZE = 47700\n",
    "EVAL_SIZE  = 13355\n",
    "\n",
    "result = loaded_model.fit(x=training,\n",
    "  epochs=100,\n",
    "  initial_epoch=0, # REMEMBER TO CHANGE THIS INITIAL EPOCH PARAM, WHEN OTHER MODEL HAS BEEN LOADED\n",
    "  steps_per_epoch=int(TRAIN_SIZE / BATCH_SIZE),\n",
    "  verbose=1,\n",
    "  shuffle=True,\n",
    "  validation_data=evaluation,\n",
    "  validation_steps=EVAL_SIZE,\n",
    "  callbacks = [cp_callback,img_callback,tensorboard,earlyStopping_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "kernel_buffer   = [256, 256]\n",
    "ROOT_PATH      = './'\n",
    "MOSAIC_VERSION = '1'\n",
    "mosaic_scale   = 30\n",
    "GRIDS_IDS    = pygeoj.load(f'{ROOT_PATH}/GRIDS/GRID-ALLCALSSES-COL9.geojson')\n",
    "GRID         = pygeoj.load(f'{ROOT_PATH}/GRIDS/GRID-ALLCALSSES-COL9-STACK.geojson')\n",
    "\n",
    "reduced_grid = [int(feature.properties['id']) for feature in GRIDS_IDS if feature.properties['apicum'] == 1]\n",
    "reduced_grid = [int(n + 1) for n in reduced_grid]\n",
    "reduced_grid.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export mosaics to GDrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doExport(out_image_base,year,region_id, kernel_buffer, roi):\n",
    "  \"\"\"Run the image export task.\"\"\"\n",
    "  image = ee.Image('projects/'+USER_EE_PROJECT+'/assets/USER_PATH/mosaic_'+str(year))\n",
    "  # Export the image, specifying scale and region.\n",
    "  task = ee.batch.Export.image.toDrive(\n",
    "    image          = image.select(BANDS).toFloat(),\n",
    "    description    = out_image_base+'_'+str(year),\n",
    "    fileNamePrefix = out_image_base+'_'+str(year), \n",
    "    folder         = 'mosaics_landsat/'+str(year),\n",
    "    scale          = 30,\n",
    "    region         = roi,\n",
    "    fileFormat     = 'GEOTIFF',\n",
    "    formatOptions  = { \n",
    "      'patchDimensions': KERNEL_SHAPE,\n",
    "      'kernelSize': kernel_buffer,\n",
    "      'compressed': True,\n",
    "      'maxFileSize': 157286400\n",
    "    }\n",
    "  )\n",
    "  task.start()\n",
    "\n",
    "# Run the export.\n",
    "for region in reduced_grid.sort():\n",
    "    region_id = int(region.properties['id'])\n",
    "    image_base_name =f'v{MOSAIC_VERSION}_L9_grid_{region_id}'\n",
    "    if int(region_id):\n",
    "      print('Region:',int(region_id))\n",
    "      for y in range(1985, 2024): \n",
    "          doExport(image_base_name,y, kernel_buffer, region.geometry.coordinates[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T16:46:18.691028Z",
     "iopub.status.busy": "2025-02-17T16:46:18.690735Z",
     "iopub.status.idle": "2025-02-17T16:46:18.869674Z",
     "shell.execute_reply": "2025-02-17T16:46:18.869230Z",
     "shell.execute_reply.started": "2025-02-17T16:46:18.691003Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mosaic_predict(mosaic_lzw,year, region_id, output_path, version, kernel_dim, optical_bands, optical_indices, model, mosaic_scale, EPOCH):\n",
    "    \"\"\"Executes segmentation over mosaic data exported from EE as .geotiff\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    mosaic_lzw : geotiff\n",
    "        Geotiff data representing the LANDSAT mosaic. The region exported must be the same as the region_id\n",
    "    year : int\n",
    "        The year of said geotiff\n",
    "    region_id : int\n",
    "        The id of the geojson grid that identifies the geotiff region\n",
    "    output_path: str\n",
    "        The output path for the segmented data\n",
    "    version: int\n",
    "        The segmentation version\n",
    "    kernel_dim: int\n",
    "        The dimention of the patches to be segmented\n",
    "    optical_bands: list\n",
    "        List of optical bands present on each geotiff\n",
    "    optical_indices: list\n",
    "        List of optical indices on each geotiff\n",
    "    model: Tensorflow model\n",
    "        The model trained\n",
    "    mosaic_scale: int\n",
    "        The scale of the geotiff. Tipically, for landsat the scale is 30\n",
    "    EPOCH: int\n",
    "        The epoch of training for the model. For identification\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Geotiff\n",
    "        A geotiff corresonding to the segmentation fo the target for the mosaic_lzw\n",
    "    \"\"\"\n",
    "\n",
    "    paths_to_check = [\n",
    "        f'{output_path}/{year}/e{EPOCH}/outimage_v{version}_e{EPOCH}_grid_{region_id}_{year}_lzw.tif',\n",
    "        f'{output_path}/{year}/e{EPOCH}/outimage_v{version}_e{EPOCH}_grid_{region_id}_{year}_byte_lzw.tif',\n",
    "    ]\n",
    "    if check_file_exists(paths_to_check):\n",
    "        return f'GRID {region_id} already predicted'\n",
    "\n",
    "    with rasterio.open(mosaic_lzw, 'r') as ds:\n",
    "        arr = ds.read()\n",
    "\n",
    "    arr = np.clip(arr, 0, None)\n",
    "    img_arr_original = arr.astype(np.float32)\n",
    "\n",
    "    if img_arr_original.shape[0]> 6:\n",
    "        img_arr_original = img_arr_original[1:, :, :] # delete blue band\n",
    "    img_arr_original = np.nan_to_num(img_arr_original, nan=0.0) \n",
    "    print(f'ORIGINAL SHAPE: {img_arr_original.shape}')\n",
    "    \n",
    "    ''' MAKE THE IMAGE QUADRATIC '''\n",
    "    arr_shape_xy = np.array(img_arr_original.shape[1:])\n",
    "    min_dim = arr_shape_xy.min()\n",
    "    index_min_dim = np.where(arr_shape_xy==min_dim)[0][0]\n",
    "    if index_min_dim == 0: # [len(bands), x, y], x<y\n",
    "        img_arr = img_arr_original[:, :, :min_dim] \n",
    "    elif index_min_dim ==1:  # [len(bands), x, y], x>y\n",
    "        img_arr = img_arr_original[:, :min_dim, :]\n",
    "    \n",
    "    ''' ENSURE IMAGE DIMENSIONS ARE MULTIPLES OF kernel_dim '''\n",
    "    \n",
    "    pad_size = (kernel_dim - (min_dim % kernel_dim)) % kernel_dim\n",
    "    \n",
    "    if pad_size > 0:\n",
    "        img_arr = np.pad(img_arr, ((0, 0), (0, pad_size), (0, pad_size)), mode='mean') # Pads with the edge values of array.\n",
    "\n",
    "    disired_dims    = kernel_dim*2 \n",
    "    bands           = optical_bands + optical_indices\n",
    "    patches         = patchify(img_arr, (len(bands), disired_dims, disired_dims), step=kernel_dim)\n",
    "    dim             = patches.shape[1]\n",
    "    patch2          = patches.reshape((1, dim**2, len(bands), disired_dims, disired_dims))\n",
    "    patch2_reshaped = patch2[0].reshape((dim**2, len(bands), disired_dims, disired_dims))\n",
    "    patch3          = np.transpose(patch2_reshaped, [0,2,3,1])\n",
    "\n",
    "    curr_patch      = tf.data.Dataset.from_tensor_slices(patch3).batch(1)\n",
    "    with tf.device('/device:GPU:0'):\n",
    "        predictions_arr = model.predict(curr_patch, batch_size=8,steps=None, verbose=1)\n",
    "    patchesPerRow  = dim\n",
    "    TotalPatches   = dim**2\n",
    "    patchDimension = [disired_dims,disired_dims]\n",
    "\n",
    "    counter       = 1\n",
    "    rowCounter    = 1\n",
    "    globalCounter = 0\n",
    "    finalArray    = np.array([])\n",
    "    rowArray      = np.array([])\n",
    "\n",
    "    for raw_record in predictions_arr:\n",
    "        raw_record = np.squeeze(raw_record)\n",
    "        rows,cols = raw_record.shape\n",
    "\n",
    "        limite_esquerda = kernel_dim//2\n",
    "        limite_direita  = kernel_dim + (kernel_dim//2)\n",
    "        limite_inferior = kernel_dim + (kernel_dim//2)\n",
    "        limite_superior = kernel_dim//2\n",
    "        if rowCounter == 1: # FIRST ROW\n",
    "            limite_superior = 0 \n",
    "        if (counter == 1) or (counter == patchesPerRow+1): # FIRST COLUMN\n",
    "            limite_esquerda = 0\n",
    "        if (counter == patchesPerRow+1) and rowCounter == 1: # FIRST COLUMNS ON SECUND ROW\n",
    "            limite_superior = kernel_dim//2  \n",
    "\n",
    "        if counter == patchesPerRow:  # LAST COLUMN\n",
    "            limite_direita = kernel_dim * 2 \n",
    "\n",
    "        if rowCounter == (TotalPatches/patchesPerRow) or (rowCounter == (TotalPatches/patchesPerRow)-1 and counter == patchesPerRow+1):  # LAST ROW\n",
    "            limite_inferior = kernel_dim * 2\n",
    "        raw_record = raw_record[limite_superior:limite_inferior,limite_esquerda:limite_direita]\n",
    "        if rowCounter == 1:\n",
    "            finalArray = rowArray\n",
    "        if counter <= patchesPerRow:\n",
    "            if counter == 1:\n",
    "                rowArray = raw_record\n",
    "            else:\n",
    "                rowArray = np.concatenate((rowArray,raw_record), axis = 1)\n",
    "            counter = counter+1\n",
    "        else:\n",
    "            counter = 2\n",
    "            rowCounter = rowCounter+1\n",
    "            if np.array_equal(finalArray,rowArray):\n",
    "                finalArray = rowArray\n",
    "            else:\n",
    "                finalArray = np.concatenate((finalArray,rowArray),axis=0)\n",
    "            rowArray = raw_record\n",
    "        globalCounter = globalCounter+1\n",
    "    finalArray = np.concatenate((finalArray,rowArray),axis=0)\n",
    "\n",
    "\n",
    "    finalArray_padded = dynamic_slice_or_pad(arr_shape_xy, finalArray)\n",
    "    print(f'finalArray_padded: {finalArray_padded.shape}\\n\\n')\n",
    "    \n",
    "    rows,cols = finalArray_padded.shape\n",
    "    finalArray_padded = np.array([finalArray_padded]) \n",
    "\n",
    "    output_path = f'{output_path}/{year}/e{EPOCH}'\n",
    "    create_directory(output_path)\n",
    "    raster_uri     = output_path + '/UNET_v'+version+'grid'+str(region_id)+'_'+str(year)+'.tif'\n",
    "    try:\n",
    "        if not np.any(np.isnan(finalArray_padded)):\n",
    "            finalArray_padded = np.round((finalArray_padded.astype(np.float32))*255).astype(np.uint8)\n",
    "        raster_uri_lzw = f'{output_path}/outimage_v{version}_e{EPOCH}_grid_'+str(region_id)+'_'+str(year)+'_byte_lzw.tif'\n",
    "        data_type = \"uint8\"\n",
    "    except Exception as inst:\n",
    "        print(f'ERROR: For grid {region_id} \\n {inst.args}, {inst}\\n Raster in float')\n",
    "        raster_uri_lzw = f'{output_path}/outimage_v{version}_e{EPOCH}_grid_'+str(region_id)+'_'+str(year)+'_float_lzw.tif'\n",
    "        data_type = \"float32\"  \n",
    "    \n",
    "\n",
    "    with rasterio.open(raster_uri,'w',\n",
    "                  driver=\"GTiff\",\n",
    "                  height=rows,\n",
    "                  width=cols,\n",
    "                  count=1,\n",
    "                  dtype=data_type,\n",
    "                  crs='EPSG:4326',\n",
    "                  transform=ds.transform,\n",
    "                  nodata=0) as dataset:\n",
    "                      dataset.write(finalArray_padded)\n",
    "    dataset = gdal.Open(raster_uri, gdal.GA_Update)\n",
    "    !gdal_translate -of GTiff -ot Byte -co \"COMPRESS=LZW\" -co \"PREDICTOR=2\" -co \"TILED=YES\" {raster_uri} {raster_uri_lzw} \n",
    "    !rm {raster_uri}\n",
    "    print(\"C'est finiz\\n\\n\")\n",
    "    return f'GRID {region_id} predito'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T16:46:23.955349Z",
     "iopub.status.busy": "2025-02-17T16:46:23.955056Z",
     "iopub.status.idle": "2025-02-17T16:46:23.960787Z",
     "shell.execute_reply": "2025-02-17T16:46:23.960209Z",
     "shell.execute_reply.started": "2025-02-17T16:46:23.955327Z"
    }
   },
   "outputs": [],
   "source": [
    "def dynamic_slice_or_pad(target_shape, predicted_img):\n",
    "\n",
    "    \"\"\"Add padding to the segmentation output so that it mayches the mosaic geotiff input dimentions\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    target_shape : list\n",
    "        List with the size of total rows and columns of the input image\n",
    "    predicted_img : Numpy array\n",
    "        Array repreenting the segmented output\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Numpy array\n",
    "        Numpy array representing the segmentation output properly padded\n",
    "    \"\"\"\n",
    "    target_rows, target_cols = target_shape\n",
    "    pad_rows = target_rows - predicted_img.shape[0]\n",
    "    pad_cols = target_cols - predicted_img.shape[1]\n",
    "\n",
    "    if pad_rows < 0:\n",
    "        predicted_img = predicted_img[:target_rows, :]\n",
    "    elif pad_rows > 0:\n",
    "        predicted_img = np.pad(predicted_img, ((0, pad_rows), (0, 0)), mode='constant')\n",
    "\n",
    "    if pad_cols < 0:\n",
    "        predicted_img = predicted_img[:, :target_cols]\n",
    "    elif pad_cols > 0:\n",
    "        predicted_img = np.pad(predicted_img, ((0, 0), (0, pad_cols)), mode='constant')\n",
    "    \n",
    "    return predicted_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T17:34:16.491873Z",
     "iopub.status.busy": "2025-02-17T17:34:16.491468Z",
     "iopub.status.idle": "2025-02-17T17:38:04.841354Z",
     "shell.execute_reply": "2025-02-17T17:38:04.840449Z",
     "shell.execute_reply.started": "2025-02-17T17:34:16.491847Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "for year in range(2023,2024):\n",
    "    print(f'/n/nYEAR:{year}')\n",
    "    i = 0\n",
    "    add_list=[]\n",
    "    for region_id in reduced_grid:\n",
    "        print(f'REGION ID {region_id}')\n",
    "        tf.keras.backend.clear_session()\n",
    "        start = time.time()\n",
    "        # try:\n",
    "        MOSAC_PATH    = f'{ROOT_PATH}/mosaico_landsat/{year}'\n",
    "        search_pattern = os.path.join(MOSAIC_PATH, f'v{MOSAIC_VERSION}_*_L*_grid_{region_id}_{year}*.tif')\n",
    "        matching_files = glob.glob(search_pattern)\n",
    "        \n",
    "        if matching_files:\n",
    "            i = i+1\n",
    "            region_mosaic_file = matching_files[0]\n",
    "            mosaic_predict(region_mosaic_file, year, region_id, OUTPUT_PATH, VERSION, KERNEL_SIZE, opticalBands, opticalIndices, loaded_model, mosaic_scale)\n",
    "        else:\n",
    "            print(i)\n",
    "            logging.error(\"No matching:\",search_pattern)\n",
    "            add_list.append(region_id)\n",
    "            print(\"No matching:\",search_pattern)\n",
    "\n",
    "end = time.time()\n",
    "print(add_list)\n",
    "print('Prediction Time per year = '+str(end - start))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0rc1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "ead1b95f633dc9c51826328e1846203f51a198c6fb5f2884a80417ba131d4e82"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
